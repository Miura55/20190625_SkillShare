{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Code for AICHIスキルシェア（Visual Recognition編）\n",
    "このパートでは画像認識を行うためのAPIである、「Watson Visual Recognition」を触ってみます。ここではLanguage Translatorのデモを終えてる前提で話を進めます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは、Visual Recognitionのリソースを作成します。その後、サービス資格情報から以下の情報を入力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY='DtImtxG68R1KHtJPyzxHaQuTwwXdB7fy8iyLqRDphQP-'\n",
    "API_URL='https://gateway.watsonplatform.net/visual-recognition/api'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に下記のセルを実行し、Watson APIのpython SDKをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade \"ibm-watson>=3.0.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のセルを実行し実際にAPIを呼び出します。versionの項目は特に指定がなければ、 https://cloud.ibm.com/apidocs/visual-recognition?code=python#versioning を確認し、最新バージョンを指定しましょう。（2019年6月現在は```2018-03-19```が最新バージョンです）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import VisualRecognitionV3\n",
    "\n",
    "visual_recognition = VisualRecognitionV3(\n",
    "    version='2018-03-19',\n",
    "    iam_apikey=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで準備ができました。では、次からは画像認識をやっていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 画像認識（一般モデル）-URLを指定する-\n",
    "事前学習済みの分類器を使った出力します。般モデルでは、数千種類の様々なクラス・キーワードから該当するものを識別します。いわゆる画像へのタグ付けです。クラス・キーワード（タグ）は、階層的にカテゴライズされていて、最上位カテゴリーとしては、動物、 人間および個人とそのアクティビティ、食品、植物、スポーツ、自然、運輸、家具、フルーツ、楽器、工具、色、装置・機器、武器、建物、構造物・人工物、衣類等々があります。（参考：https://cloud.ibm.com/apidocs/visual-recognition?code=python#classify-images ）\n",
    "- 入力：認識させたい画像ファイル（jpegかpng）またはURL\n",
    "- 出力\n",
    " - 画像に写っているもの、分類結果\n",
    " - スコア（画像の確信度）\n",
    " - もの・分類結果の階層構造 (動物-家畜-犬-小型犬･･･といったタグの階層)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはサンプル画像のURLから画像認識をやっていきます（[このリンクの画像](https://watson-developer-cloud.github.io/doc-tutorial-downloads/visual-recognition/fruitbowl.jpg)を使います）。下記のセルを実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = 'https://watson-developer-cloud.github.io/doc-tutorial-downloads/visual-recognition/fruitbowl.jpg'\n",
    "\n",
    "import json\n",
    "\n",
    "classes = visual_recognition.classify(\n",
    "        url=image_url,\n",
    "        threshold='0.6',\n",
    "        accept_language='ja').get_result()\n",
    "print(json.dumps(classes, indent=2,  ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうですか？JSONの形式で結果が出力されたと思います。さらにその結果が日本語で出力されていることが分かるかと思います。これは```accept_language```で言語のIDを指定することで出力されます。指定できる言語は11言語でデフォルトは```en```です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 画像認識（一般モデル）-自前で用意する-\n",
    "では、今度は自前で用意した画像を読み込ませる作業を行います。皆さんのPC上に保存されている画像をなんでもいいので用意してください。（ない場合は[こちらの画像](https://github.com/Miura55/20190625_SkillShare/blob/master/img/ramen.jpeg)をご自分のPCにインストールしてください。）\n",
    "用意したら、Watson Studioで画像を取り込む作業を行う必要があります。以下の作業を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 右上のアイコンの中から正方形が3つと数字の１で構成されたアイコンを探し、クリックします。\n",
    "2. ```files```タブを選択されていることを確認し、画像を```Drop your file here or browse your files to add a new file```にドラッグ＆ドロップするか、```browse```をクリックして画像ファイルを選択します。\n",
    "3. 下記のセルをクリックし、```Insert to code```を選択し、```Insert StreamingBody object```をクリックしてファイルを読み込むためのコードを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
     "# ここをクリックして生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コードが生成できたら、今度は画像をストレージに保存することなくプログラム上だけで処理できるようにファイルのコピーを行います。下のセルを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "filename = \"ramen.jpeg\"\n",
    "file = BytesIO(streaming_body_1.read())\n",
    "with open(filename, \"wb\") as out:\n",
    "    out.write(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像のコピーが出来ているか確認するために実際に画像を表示させてみます。下のセルを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# 画像が読み込めたかを確認\n",
    "with open(filename, 'rb') as images_file:\n",
    "    image = Image.open(filename)\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いよいよ読み込んだ画像を認識していきます。下記のセルを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'rb') as images_file:\n",
    "    classes = visual_recognition.classify(\n",
    "        images_file,\n",
    "        threshold='0.6',\n",
    "       accept_language='ja').get_result()\n",
    "    print(json.dumps(classes, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. もう少し見やすくしてみる\n",
    "ここまでで画像を読み込んで認識させる結果を見てきました。しかし、出力されるものがJSONであるため結果を見るには少し見づらいです。そこでmatplotlibを使用してグラフを表示していきます。matplotlibとは、グラフを作成するために使用されるpyhonライブラリです。先程出力したjsonファイルのうち、```class```要素をx軸のラベルにつけたいですが、日本語を入れるには別途フォントをインストールする必要があります。まずは下記のセルを実行し、日本語のフォントファイルをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#日本語フォントの導入  \n",
    "jp_font_path ='ipaexg00301/ipaexg.ttf'\n",
    "\n",
    "if not os.path.exists(jp_font_path):\n",
    "    !wget https://oscdl.ipa.go.jp/IPAexfont/ipaexg00301.zip\n",
    "    !unzip ipaexg00301.zip\n",
    "else:\n",
    "    print('IPA font haｓ been already installed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インストールを終えたら、下記のセルを実行し認識結果をグラフで表示します。(もし何もグラフが表示されない場合はもう一回セルを実行してみるとグラフが表示されると思います。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "fp = FontProperties(fname=jp_font_path, size=10)\n",
    "\n",
    "# 値を設定\n",
    "values = [value for value in classes[\"images\"][0][\"classifiers\"][0][\"classes\"]]\n",
    "label = [label[\"class\"] for label in values]\n",
    "plt.xticks(range(len(values)), label, fontproperties=fp, rotation=45)\n",
    "\n",
    "# グラフを表示\n",
    "plt.bar(range(len(values)), [score[\"score\"] for score in values], color=\"blue\")\n",
    "plt.show()\n",
    "\n",
    "# 結果一覧を表示\n",
    "df_face_detect_res = pd.DataFrame({\"score\":[score[\"score\"] for score in values]},\n",
    "                                 index=label)\n",
    "display(df_face_detect_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 顔認識にチャレンジ\n",
    "ここまでは物体認識の話を取り上げてきましたが、ここからは人の顔を認識することをやっていきます。Visual Recognitionには顔認識専用のモデルもデフォルトに存在し、顔の位置、年齢、性別などを判定してくれます。それでは、下記のセルを実行し、画像のインストールと使うか画像を見ていきます。今回の画像はネットで見つけたフリー素材です。（リンクが無効になって使えなくなる可能性があります）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://skybiometry.com/wp-content/uploads/2015/09/work-2-1-e1451907791984.jpg -O people.jpg\n",
    "\n",
    "with open(\"./people.jpg\", \"rb\"):\n",
    "    image = Image.open(\"./people.jpg\")\n",
    "    display(image)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、インストールした画像を実際に認識させてみましょう。下記のセルを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./people.jpg', 'rb') as images_file:\n",
    "    faces = visual_recognition.detect_faces(images_file).get_result()\n",
    "print(json.dumps(faces, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なんとなく認識されていることが分かりますがこれでは、どの顔がどのように認識されているのかわかりません。そこで画像に印をつけて顔認識結果がわかるように下記の関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw,ImageFont\n",
    "import os\n",
    "\n",
    "def draw_face_area(image_file, face_detect_res):\n",
    "    \n",
    "    if  len(face_detect_res) < 1:\n",
    "        print('No face detection')\n",
    "        return        \n",
    "    \n",
    "    image = Image.open(image_file)\n",
    "    draw = ImageDraw.Draw(image, \"RGBA\")\n",
    "    #日本語フォントの導入  \n",
    "    jp_font_path ='ipaexg00301/ipaexg.ttf'\n",
    "\n",
    "    if not os.path.exists(jp_font_path):\n",
    "        !wget https://oscdl.ipa.go.jp/IPAexfont/ipaexg00301.zip\n",
    "        !unzip ipaexg00301.zip\n",
    "    else:\n",
    "        print('IPA font haｓ been already installed')\n",
    "    \n",
    "    col_name =  [\"gender\", \"gender_score\", \"age_max\", \"age_min\", \"age_score\"]\n",
    "    df_face_detect_res = pd.DataFrame(columns=[])\n",
    "  \n",
    "    for i, faceinfo in enumerate(face_detect_res):\n",
    "        x0 = faceinfo['face_location']['left']\n",
    "        x1= x0 +  faceinfo['face_location']['width']\n",
    "        y0 = faceinfo['face_location']['top']\n",
    "        y1 = y0 + faceinfo['face_location']['height']\n",
    "        \n",
    "        \n",
    "        df_face_detect_res.loc[i, \"gender\"] = faceinfo['gender']['gender']\n",
    "        df_face_detect_res.loc[i, \"gender_score\"] = faceinfo['gender']['score']\n",
    "        df_face_detect_res.loc[i, \"age_max\"] = faceinfo['age']['max']\n",
    "        df_face_detect_res.loc[i, \"age_min\"] = faceinfo['age']['min']\n",
    "        df_face_detect_res.loc[i, \"age_score\"] = faceinfo['age']['score']\n",
    "        \n",
    "        font_size = 20\n",
    "        font = ImageFont.truetype(jp_font_path, font_size)\n",
    "        text_size = draw.textsize('88', font=font)\n",
    "        if not ( x1-x0 < text_size[0] or y1-y0 < text_size[1]):\n",
    "            while x1-x0 > text_size[0] or y1-y0 > text_size[1]:\n",
    "                font = ImageFont.truetype(jp_font_path, font_size)\n",
    "                text_size = draw.textsize('88', font=font)\n",
    "                font_size += 1\n",
    "            \n",
    "        font = ImageFont.truetype(jp_font_path, font_size)\n",
    "        draw.rectangle(xy=(x0,y0, x1, y1), outline=(0, 249, 0))\n",
    "        draw.text(xy=(x0+5,y0+5), text=str(i), fill=(0, 249, 0), font=font)\n",
    "        \n",
    "    display(image)\n",
    "    pd.options.display.max_rows = None\n",
    "    display(df_face_detect_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "関数を定義して以下のセルを実行します。画像上で認識された顔に番号が振られ、更に性別、大体の年齢、それぞれのスコアを表で出力されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_face_area('people.jpg', faces['images'][0]['faces'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "それでは、最後にご自分で画像を用意して顔認識を行ってください。パソコンに保管されているものでもオンラインにあるものでも大丈夫ですが、それぞれで必要な処理がありますので、忘れずに行ってください。プログラムはこの下にセルを追加していきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
